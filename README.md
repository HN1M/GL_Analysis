다음은 기존 `README.md` 파일에 신규 기획안을 반영하여 업데이트한 내용입니다. 핵심 아키텍처 개선 계획을 문서 상단에 배치하여 주요 변경 사항을 강조했으며, 기존 세부 명세와 자연스럽게 연결되도록 내용을 수정 및 보강했습니다.

-----

## 📜 GL 분석 시스템 최종 청사진 (To-Be Model)

### **✨ 핵심 아키텍처 및 기능 개선 계획**

이 문서는 GL 분석 시스템의 핵심 아키텍처 결정사항과 향후 발전 방향을 정의합니다. 시스템의 목표는 독립된 분석 도구의 집합을 넘어, 모든 분석 결과가 유기적으로 통합되고 사용자의 전문적 통찰력이 결합되어 최종 분석 결과물의 깊이를 더하는 \*\*'지능형 분석 파트너'\*\*로 진화하는 것입니다.

**1. DTO 중심의 중앙화된 분석 파이프라인**

시스템의 모든 데이터 흐름은 \*\*표준화된 데이터 전송 객체(DTO)인 `ModuleResult`\*\*를 중심으로 이루어집니다. 이는 각 분석 모듈의 독립성을 보장하고, 전체 파이프라인의 예측 가능성과 확장성을 극대화합니다.

  - **표준 DTO `ModuleResult`**: 모든 분석 모듈(`anomaly.py`, `vendor.py` 등)은 실행 후 반드시 `ModuleResult` 객체를 반환해야 합니다. 이 객체는 다음과 같은 표준화된 정보를 담는 컨테이너입니다.
      - `summary`: LLM 컨텍스트에 사용될 핵심 요약 지표
      - `tables`: UI에 표시될 `pd.DataFrame`
      - `figures`: UI에 표시될 `Plotly Figure`
      - `evidences`: 가장 중요한 요소로, 분석 과정에서 발견된 모든 구조화된 증거(`EvidenceDetail` 객체) 리스트
  - **중앙 오케스트레이션**: `app.py`는 중앙 관제탑 역할을 합니다. 전체 분석 실행 시, 모든 분석 모듈을 순차적으로 호출(`run_all_modules`)하고 반환된 `ModuleResult` 리스트를 세션(`st.session_state`)에 저장합니다. 이후 모든 UI 탭과 최종 보고서 생성 로직은 이 세션에 저장된 사전 계산된 결과만을 사용하며, 중복 계산을 원천적으로 방지합니다.
  - **다중 소스 컨텍스트 주입**: 최종 분석 보고서(또는 프롬프트)는 다음과 같은 세 가지 소스를 종합하여 생성됩니다.
    1.  **System-Generated Evidences**: 각 분석 모듈이 생성한 `ModuleResult` 내의 모든 증거.
    2.  **Auditor's Insights**: 사용자가 UI를 통해 직접 입력하는 전문적 소견 및 메모.
    3.  **External Sources**: 사용자가 외부에서 조사하여 시스템에 제공하는 추가 정보 (뉴스, 공시 등).

**2. 프롬프트 제공 기능 (Prompt-as-a-Service)**

보안이 중요한 배포 환경을 고려하여, 시스템은 LLM을 직접 호출하는 대신 최종적으로 완성된 고품질의 프롬프트를 생성하여 제공하는 옵션을 갖습니다.

  - **보안 및 유연성**: 사내 데이터의 외부 API 전송이 금지된 환경에서도 이 시스템을 안전하게 활용할 수 있습니다. 분석가는 로컬 또는 내부 서버에서 시스템을 실행하여 민감 데이터를 처리하고, 그 결과로 생성된 데이터가 풍부하게 포함된 프롬프트만을 복사합니다.
  - **워크플로우**: 사용자는 이렇게 생성된 프롬프트를 조직에서 승인한 상용 LLM(ChatGPT, Claude 등) 환경에 직접 붙여넣어 최종 보고서를 얻을 수 있습니다. 이는 분석 로직과 LLM 호출을 물리적으로 분리하여 보안 규정을 준수하면서도 최신 LLM의 성능을 활용할 수 있게 합니다.

**3. 임베딩을 활용한 이상 패턴 탐지 고도화**

기존에 AI 리포트 생성 단계에만 머물러 있던 벡터 임베딩 프로세스를 이상 패턴 탐지 모듈(`analysis/anomaly.py`)로 전진 배치하여, 분석의 깊이를 획기적으로 향상시킵니다.

  - **다차원 이상치 분석**: 이 변화를 통해 시스템은 단순히 '금액'만 보는 것을 넘어, 거래의 '의미'까지 종합적으로 판단하는 고차원 분석을 수행합니다.
      - **의미 기반 이상치 (Semantic Outliers)**: 각 계정별로 모든 거래(적요) 벡터의 \*\*평균 벡터(Centroid Vector)\*\*를 계산합니다. 개별 거래의 벡터가 자신이 속한 계정의 평균 벡터와 의미적으로 거리가 멀 경우(예: '복리후생비' 계정에 '서버 임차료' 거래), 이를 계정 분류 오류 가능성이 높은 이상치로 탐지합니다.
      - **복합 피처 활용**: Isolation Forest와 같은 머신러닝 모델에 수치 데이터(거래 금액 등)와 텍스트의 벡터 표현을 함께 입력합니다. 이를 통해 "금액은 크지 않지만 내용이 매우 이례적이거나" 혹은 "내용은 평범하지만 금액이 비정상적인" 복합적인 이상 패턴을 효과적으로 식별할 수 있습니다.

      - **[제안] 계정 내 하위 클러스터링(Sub-Clustering)**:
        - **문제 인식**: '잡이익', '기타비용'처럼 다양한 성격의 거래가 혼재된 계정에서는 단일 Centroid가 의미를 희석시켜 이상치 탐지 정확도가 낮아질 수 있습니다.
        - **해결 방안**: 계정 단위로 임베딩을 먼저 하위 클러스터링(예: K-Means/HDBSCAN)한 뒤, 각 하위 클러스터의 Centroid와의 거리를 기준으로 이상치를 판단합니다. 동질적 거래 그룹 내부에서의 이탈을 정교하게 포착할 수 있습니다.
        - **구현 포인트**: `analysis/anomaly.py`에 Sub-Clustering 옵션 추가, `analysis/embedding.py`의 K-Means/HDBSCAN 유틸 재사용, k 자동선정(silhouette 등) 또는 HDBSCAN 기본 파라미터 적용, `EvidenceDetail`에 `cluster_id/cluster_name` 포함.
        - **현황**: 시스템은 이미 임베딩 및 클러스터링을 수행하며(`analysis/embedding.py`), LLM 기반 이름 부여/정렬을 지원합니다. 본 제안은 이를 이상치 탐지(계정 단위)에도 직접 적용하는 확장입니다.

**B. AI 모델의 신뢰성 및 설명가능성 확보 (XAI & HITL)**

감사/재무 분석 환경에서는 AI 판단 이유와 전문가 개입이 중요합니다.

- **설명가능한 AI(XAI) — SHAP 도입(계획)**
  - **현황**: `anomaly.py`에서 Isolation Forest 등 모델 해석이 어렵습니다.
  - **제안**: SHAP을 도입해 이상치 판정에 기여한 피처(금액, 텍스트 이례성, 시간 등)를 수치화하고, 결과를 `EvidenceDetail`에 포함(설명 필드)하여 근거로 활용합니다.

- **Human-in-the-Loop(HITL) 피드백 루프(계획)**
  - **제안**: 이상치에 대해 사용자가 True/False Positive를 표시하도록 하고, 피드백을 축적해 임계값 조정/주기적 재학습에 활용합니다.

- **도메인 특화 임베딩(장기)**
  - **제안**: 회계/금융 특화 임베딩 모델(축약어·전문용어 반영)로 전환/병행해 의미 유사도·클러스터 품질 향상.

**C. 위험 점수 산정 체계의 정교화 (Risk Score Calibration)**

모듈별 risk_score 스케일 불일치를 중앙에서 보정합니다.

- **중앙 위험 점수 조정 레이어(계획)**
  - `analysis/risk_calibration.py`를 도입. 각 모듈은 Raw Score를 반환하고, 중앙 레이어가 0~1로 정규화/스케일링해 통합 점수를 산출합니다.

- **PM 결합 공식/가중치 설정(계획)**
  - 통계적 유의성(원시 점수)과 재무적 영향(PM 대비)을 결합하는 공식을 정의하고, `config.py`에서 모듈별 가중치를 관리합니다.

**4. 레거시 보고서 유지 및 표준화**

LLM을 사용하지 않는 환경이나 빠른 요약이 필요할 때를 대비하여, 기존의 로컬 규칙 기반 보고서(`run_offline_fallback_report`) 기능을 유지하되, 새로운 DTO 표준에 맞게 재구성합니다.

  - **오프라인 폴백 기능**: API 키가 없거나, LLM 호출 비용/시간을 절약하고 싶을 때를 위한 효율적인 대안으로 활용됩니다. Z-Score 상위 항목, KIT(Key Item Test) 통과 항목 등 핵심적인 수치 기반의 요약을 제공합니다.
  - **DTO 호환성 확보(계획)**: 보고서 생성 전 과정을 `ModuleResult` 표준으로 통일하는 방향입니다. 현행 코드는 레거시 DF 경로를 어댑터(`analysis/report_adapter.py`)로 감싸 호환합니다.

-----

**Ⅰ. 사용자 페르소나 및 핵심 시나리오** 🧑‍💻

  - **목표**: '누가', '왜', '어떻게' 이 툴을 사용하는지 명확히 하여, 기능 개발의 우선순위를 정하고 UX를 개선합니다.
  - **상세 명세**:
      - **페르소나 정의**:
          - **`김감사 (3년차 회계법인 감사인)`**: 감사 조서 작성 시간을 단축하고 싶어 함. 이상 거래 샘플링의 근거를 찾는 데 많은 시간을 소요.
          - **`박팀장 (10년차 기업 재무팀장)`**: 월 결산 후 내부 검토용으로 재무 데이터의 특이사항을 빠르게 파악하고 싶어 함. 경영진 보고 자료에 포함할 인사이트가 필요.
      - **핵심 시나리오 (User Stories)**:
          - **"김감사는** 매출 계정의 급증 원인을 파악하기 위해, `위험 평가` 탭에서 '매출'과 'E(실재성)'가 교차하는 셀을 클릭하여 가장 위험도가 높은 거래 내역을 드릴다운하고, 해당 내역을 CSV로 추출하여 감사 조서에 첨부한다."
            (⚠️ 임시 비활성화) `위험 평가` 탭 관련 시나리오는 현재 제거되어, 프로젝트 말미에 재도입 예정입니다.
          - **"박팀장은** 광고선전비 계정을 `AI 리포트`에서 분석하여, '신규 캠페인' 클러스터가 전기 대비 크게 증가했음을 확인하고, 해당 내용을 요약하여 월간 실적 보고 회의에 사용한다."

-----

### Ⅱ. 핵심 설계 원칙 (Core Principles)

1.  **계층 분리 (Layered Architecture)**: 모든 코드는 \*\*UI(`app.py`) ↔ 서비스(`services/`) ↔ 분석(`analysis/`) ↔ 데이터(`contracts.py`)\*\*의 4개 계층으로 엄격히 분리됩니다. 계층 간 호출은 상위에서 하위로만 가능하며, **`analysis/` 모듈은 절대 `services/`나 `ui/`를 호출할 수 없습니다.**
2.  **표준 입출력 계약 (Standard I/O Contracts)**: 모든 분석 모듈은 표준 데이터 구조인 \*\*`LedgerFrame`을 입력받고, 결과물로 표준 DTO(Data Transfer Object)인 \*\*`ModuleResult`를 반환해야 합니다. 이는 모듈의 독립성과 조합성을 보장합니다.
3.  **상태 없음 (Stateless Modules)**: `analysis/` 모듈은 내부 상태를 가지지 않는 순수 함수(Pure Function)처럼 동작해야 합니다. 동일 입력에 대해 항상 동일 출력을 보장하여 예측 가능성과 테스트 용이성을 높입니다.
4.  **중앙화된 외부 연동 (Centralized Services)**: LLM 호출, 외부 API(휴일 정보 등), 캐시 관리 등 모든 외부 의존성은 `services/` 계층에서만 처리합니다. 분석 로직의 순수성을 유지하기 위함입니다.
5.  **위험 중심 설계 (Risk-Driven Design)**: 모든 분석 결과(`EvidenceDetail`)는 최종적으로 통계적 유의성과 재무적 중요성(**PM**)을 결합한 **통합 위험 점수**로 귀결되어야 합니다.

-----

### **Ⅲ. 데이터 계약 (Data Contracts)** 📜

  - **목표**: 시스템 전체에서 데이터가 이동하는 형태를 명확히 정의하여, 모듈 간의 안정적인 통신을 보장합니다.
  - **담당 모듈**: `analysis/contracts.py`
  - **상세 명세**:
    1.  **`LedgerFrame`**: 모든 분석 모듈의 **표준 입력**.
          - `df`: 표준화된 컬럼(`회계일자`, `계정코드`, `거래금액_절대값` 등)을 가진 Pandas DataFrame.
          - `meta`: 원본 파일명, 분석 기간, `master_df` 등 분석에 필요한 메타 정보를 담는 딕셔너리.
    2.  **`ModuleResult`**: 모든 분석 모듈의 **표준 출력**. (❗️ **시스템 아키텍처의 핵심**)
          - `name`: 모듈 이름 (e.g., "anomaly").
          - `summary`: LLM 보고서 컨텍스트에 직접 사용될 핵심 수치 요약 딕셔너리.
          - `tables`: 화면에 표시할 `pd.DataFrame` 딕셔너리.
          - `figures`: 화면에 표시할 `Plotly Figure` 딕셔너리.
          - `evidences`: 모든 발견 사항을 담는 **`EvidenceDetail`** 객체 리스트. **가장 중요한 결과물.**
          - `warnings`: 분석 중 발생한 경고 메시지 리스트.
    3.  **`EvidenceDetail`**: 개별 분석 결과(이상치, 예측 이탈 등)를 담는 **표준 원자 단위**.
          - `row_id`: 원본 데이터 추적을 위한 고유 ID.
          - `reason`: 발견 사유 (e.g., "|Z|=3.5").
          - `risk_score`: 통합 위험 점수 (0\~1).
          - `financial_impact`: 재무적 중요성 (거래금액 절대값).
          - `is_key_item`: PM 초과 여부 (boolean).
          - `impacted_assertions`: 연관된 주장위험 리스트 (e.g., `["C", "A"]`).
          - `links`: 계정코드, 계정명 등 드릴다운 및 상호 참조에 필요한 메타 정보.

-----

### Ⅳ. 시스템 아키텍처 및 데이터 흐름

```lua
+------------------+      +-------------------+      +---------------------+      +-----------------+
|   UI (app.py)    |----->|  Services Layer   |----->|   Analysis Layer    |----->|  Data Contract  |
| (Streamlit)      |      | (LLM, Cache, API) |      | (Pandas, Stats)     |      | (LedgerFrame,   |
| - 사용자 입력    |      | - LLM 호출/요약   |      | - 순수 계산/분석    |      |  ModuleResult)  |
| - 결과 시각화    |      | - 캐시 관리       |      | - ModuleResult 생성 |      | - 데이터 구조   |
+------------------+      +-------------------+      +---------------------+      +-----------------+

```

1.  **`app.py`**: 사용자가 파일을 업로드하고 분석 옵션(기간, 계정, PM)을 설정합니다.
2.  **`app.py` → `analysis/` (중앙 오케스트레이션)**: 분석 실행 버튼 클릭 시, `app.py`는 `LedgerFrame`을 구성하여 **모든 분석 모듈을 순차적으로 호출**합니다. *(현행: 탭 진입/사용자 상호작용 시 개별 모듈을 지연 실행; 계획상 중앙 오케스트레이션으로 수렴)*
3.  **`analysis/` → `ModuleResult`**: 각 모듈은 분석 결과를 `ModuleResult` 객체에 담아 반환합니다.
4.  **`st.session_state`**: `app.py`는 반환된 `ModuleResult` 객체들의 리스트를 **세션 상태에 저장**합니다. 이후 모든 UI 탭은 이 사전 계산된 결과만을 참조합니다.
5.  **`app.py` (시각화)**: 각 탭은 세션에서 필요한 `ModuleResult`를 꺼내 그 안에 포함된 테이블과 플롯을 화면에 렌더링합니다.
6.  **`analysis/report.py` (보고서 생성)**: AI 리포트 생성 시, `report.py`는 세션에 저장된 **`ModuleResult` 전체 리스트**와 사용자 추가 입력을 받아 최종 LLM 컨텍스트(프롬프트)를 구성합니다.
7.  **`services/llm.py` (LLM 호출 또는 프롬프트 제공)**: `app.py`는 생성된 프롬프트를 `services` 계층에 전달하여 LLM을 호출하거나, "Prompt-as-a-Service" 모드에서는 최종 프롬프트를 UI에 표시하여 사용자가 복사할 수 있도록 합니다.

-----

### Ⅴ. 모듈별 상세 명세

| 기능 | 담당 모듈 | 역할 및 핵심 로직 | 입력 | 출력 | LLM 활용 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **데이터 정합성** | `analysis/integrity.py` | Master와 Ledger 간 기초/기말 잔액 및 당기 증감액 검증. 데이터 품질 지표(결측률, 텍스트 엔트로피 등) 계산. | `LedgerFrame` | (현행) 상태+DataFrame / (계획) `ModuleResult` | 없음 |
| **월별 추세 분석** | `analysis/trend.py` | 계정별 CY vs PY 월별 추이(발생액/잔액) 비교. BS/PL 성격과 차/대변 특성을 반영한 시각화 생성. | `LedgerFrame` | `ModuleResult` (월별 추이 Plotly Figure) | 없음 |
| **거래처 분석** | `analysis/vendor.py` | 계정별/전체 거래처 집중도(파레토), 월별 활동성(히트맵), 특정 거래처 상세 내역(누적 막대) 분석. | `LedgerFrame` | `ModuleResult` (파레토, 히트맵 등 Figure) | 없음 |
| **상관/사이클 분석** | `analysis/correlation.py` | 계정 간 월별 흐름의 상관관계(피어슨) 계산 및 히트맵 시각화. 계정명을 기반으로 표준 회계 사이클(R2C, P2P 등)을 자동 그룹화하고, 그룹 간 상관 붕괴/지연 탐지. | `LedgerFrame` | `ModuleResult` (상관 히트맵, 사이클 경고 테이블) | **[해석]** 상관 붕괴 원인 자연어 설명, **[추천]** 계정명 기반 사이클 그룹 제안 |
| **시계열 예측** | `analysis/timeseries.py` | 계정별 월별 시계열 데이터에 최적 예측 모델(MoR: EMA/MA/ARIMA/Prophet)을 자동 적용. 최종 시점의 예측-실측 간 이탈(Error)을 계산하고 z-score, 위험 점수 산출. | `LedgerFrame` | (현행) DataFrame / (계획) `ModuleResult` + Evidence | 없음 |
| **이상 패턴 탐지** | `analysis/anomaly.py` | **1) 임베딩 및 다차원 분석**(리포트 경로 중심 활용) + **2) 통계 기반(Z-Score)** 중심. (제안) 계정 내 Sub-Clustering을 이상치 판단에도 직접 활용. | `LedgerFrame` | `ModuleResult` (이상 전표 테이블, Evidence 리스트) | **[이름 부여]** LLM 기반 클러스터 네이밍/정렬(리포트 경로) |
| **AI 리포트** | `services/llm.py`, `analysis/report.py` | **1) `report.py`**: 각 `ModuleResult`의 `summary`와 `evidences`, 사용자 메모를 종합하여 최종 컨텍스트(RAG용) 생성. **2) `llm.py`**: 생성된 컨텍스트로 LLM 호출 또는 프롬프트 제공. **3) (폴백)** `run_offline_fallback_report`는 `ModuleResult` 리스트에서 필요 정보를 추출하여 규칙 기반 보고서 생성. | `List[ModuleResult]` | 최종 보고서 `string` 또는 `prompt string` | **[생성]** 종합 분석 결과를 바탕으로 최종 보고서 초안 작성 |

-----

### Ⅵ. 최종 디렉터리 구조 (To-Be Directory Structure) 📂

```lua
gl-analysis-system/
├── .streamlit/
│   └── config.toml         # Streamlit 앱 설정 (테마, 폰트 등)
├── analysis/
│   ├── contracts.py        # ❗ 데이터 계약 (LedgerFrame, ModuleResult, EvidenceDetail)
│   ├── integrity.py        # 데이터 정합성 및 품질 분석
│   ├── trend.py            # 월별 추세 분석
│   ├── vendor.py           # 거래처 심층 분석
│   ├── correlation.py      # 계정 간 상관/사이클 분석
│   ├── timeseries.py       # 시계열 예측 및 이탈 분석
│   ├── anomaly.py          # 통계/AI 기반 이상 패턴 탐지
│   ├── embedding.py        # 텍스트 임베딩 및 클러스터링 로직
├── services/
│   ├── llm.py              # LLM(OpenAI) 호출 클라이언트 및 관련 유틸
│   ├── cache.py            # 임베딩, 예측 결과 등 비용 큰 연산 캐시 관리
│   └── external.py         # (확장용) 외부 API(휴일, 뉴스 등) 연동
├── ui/
│   └── inputs.py           # (선택) Streamlit 커스텀 입력 위젯 (예: krw_input)
├── utils/
│   ├── helpers.py          # 범용 헬퍼 함수 (find_column, add_period_tag 등)
│   ├── logger.py           # 표준 로깅 설정
│   └── viz.py              # 공통 시각화 유틸 (PM 임계선 추가 등)
├── tests/
│   ├── conftest.py         # Pytest 설정
│   ├── test_anomaly.py     # 각 분석 모듈별 단위/통합 테스트
│   ├── test_timeseries.py
│   └── ... (기타 테스트 파일)
├── .env                    # ❗ (Git 무시) API 키 등 민감 정보 저장
├── app.py                  #  애플리케이션의 메인 진입점 (Streamlit)
├── config.py               # ❗ 애플리케이션 전체 설정 (PM, 모델 파라미터 등)
├── (Optional) Dockerfile   # 컨테이너화된 배포 환경 정의(현 시점 미포함)
├── (Optional) PROJECT_BLUEPRINT.md  # 기획 청사진 문서(현 시점 미포함)
└── requirements.txt        # ❗ 프로젝트 파이썬 의존성 및 버전 고정

```

-----

### Ⅶ. 환경설정 및 구성 관리 (`config.py`)

  - **목표**: 코드 변경 없이 애플리케이션의 동작을 제어할 수 있도록 모든 설정을 중앙에서 관리합니다.
  - **담당 모듈**: `config.py`
  - **상세 명세**:
      - **LLM 설정**: `LLM_MODEL` (e.g., "gpt-4o"), `LLM_TEMPERATURE` 등 API 관련 파라미터.
      - **재무적 중요성(PM)**: `PM_DEFAULT` (기본 중요 금액).
      - **분석 모델 파라미터**: `SHAP_TOP_N` (SHAP 분석 대상 수), `TIMESERIES_MIN_POINTS` (시계열 분석 최소 데이터 기간) 등 각 분석 모듈의 핵심 변수를 정의합니다.
      - **외부 서비스 정보**: API 엔드포인트, 타임아웃 값 등.
      - **보안**: `.env` 파일을 통해 관리할 민감 정보(API 키 등)의 목록을 명시하고, `config.py`는 환경 변수에서 이를 불러오도록 설계합니다.

-----

### Ⅷ. 향후 로드맵: RAG 도입을 통한 대화형 분석

장기적으로 시스템을 정적 대시보드에서 **대화형 분석 파트너**로 발전시키기 위한 아이디어입니다.

  - **의미 기반 검색 (Semantic Search)**: 사용자가 "3분기에 마케팅비가 왜 급증했어?" 또는 "A거래처와 관련된 유형자산 취득 내역 전부 보여줘" 와 같이 자연어로 질문할 수 있는 검색 기능을 도입합니다.
  - **RAG (Retrieval-Augmented Generation) 아키텍처**:
    1.  **(Indexing)**: 시스템은 GL 데이터의 모든 '적요' 텍스트를 미리 임베딩하여 검색 가능한 벡터 데이터베이스에 저장합니다.
    2.  **(Retrieval)**: 사용자의 질문이 들어오면, 질문 역시 벡터로 변환하여 벡터 DB에서 \*\*의미적으로 가장 유사한 거래 내역들을 검색(Retrieve)\*\*합니다.
    3.  **(Augmentation)**: 이렇게 찾아낸 실제 거래 데이터(증거)를 사용자의 원래 질문과 함께 LLM에 전달할 \*\*프롬프트에 보강(Augment)\*\*합니다.
    4.  **(Generation)**: LLM은 구체적인 증거에 기반하여 사용자의 질문에 대한 심층적인 답변을 \*\*생성(Generate)\*\*합니다.

-----

### Ⅸ. 테스트 및 품질 보증 (`tests/`)

  - **목표**: 코드의 정확성과 안정성을 보장하고, 변경 사항이 기존 기능에 미치는 영향을 사전에 파악합니다.
  - **담당 디렉터리**: `tests/`
  - **상세 명세**:
      - **단위 테스트 (Unit Tests)**: `analysis/` 계층의 순수 계산 함수들을 대상으로 합니다. (`tests/test_anomaly.py`, `tests/test_timeseries.py`)
          - **검증 항목**: 알려진 입력값에 대해 정확한 출력값을 반환하는지, 경계값(0, null 등)을 잘 처리하는지 검증합니다.
      - **통합 테스트 (Integration Tests)**: 데이터가 `app.py` → `analysis/` → `ModuleResult`로 흐르는 전체 파이프라인이 정상 동작하는지 검증합니다. (`tests/test_pipeline.py`)
          - **검증 항목**: 소규모 샘플 엑셀 파일을 이용해 전체 분석 실행 시 오류 없이 `ModuleResult`가 생성되는지 확인합니다.
      - **스냅샷 테스트 (Snapshot Tests)**: `ModuleResult`에 포함된 시각화 결과(Plotly Figure의 JSON 표현)나 요약 테이블이 이전 버전과 동일하게 유지되는지 비교합니다. (`tests/test_snapshots.py`)
          - **검증 항목**: 코드 변경 후 의도치 않은 UI 변경이 발생했는지 자동으로 탐지합니다.